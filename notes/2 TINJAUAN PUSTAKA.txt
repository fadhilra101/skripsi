2.1 Analisis Sepak Bola
	1. penjelasan dasar analisis sepak bola, gunakan referensi ini: Football analysis is a complex sociotechnical system that involves measuring communication, adaptability, playing at the appropriate tempo, and analyzing attacking and defending related measures.  Mclean, S., Salmon, P., Gorman, A., Read, G., & Solomon, C. (2017). What’s in a game? A systems approach to enhancing performance analysis in football. PLoS ONE, 12. https://doi.org/10.1371/journal.pone.0172565.

	2. penjelasan lanjutan,gunakan referensi ini: Football analysis involves focusing on technical, tactical, and physical performance variables in adult male football, with situational variables like game location, quality of opposing teams, and match status also playing a role. Sarmento, H., Marcelino, R., Anguera, M., Campaniço, J., Matos, N., & Leitão, J. (2014). Match analysis in football: a systematic review. Journal of Sports Sciences, 32, 1831 - 1843. https://doi.org/10.1080/02640414.2014.898852.

	3.  penjelasan mendetail,gunakan referensi ini: Football analysis involves focusing on performance at set pieces, collective system behaviors, team communication, and player activity profiles to improve player performance and coach activity. Sarmento, H., Clemente, F., Araújo, D., Davids, K., McRobert, A., & Figueiredo, A. (2018). What Performance Analysts Need to Know About Research Trends in Association Football (2012–2016): A Systematic Review. Sports Medicine, 48, 799-836. https://doi.org/10.1007/s40279-017-0836-6.
	4. menjelaskan contoh analisis sepak bola diimplementasi; refer; Tracking data in soccer analysis provides detailed insights into performance structure, revealing successful defensive play characterized by high pressure, synchronization, balanced defense, and compact coordinated organization.
Forcher, L., Altmann, S., Forcher, L., Jekauc, D., & Kempe, M. (2022). The use of player tracking data to analyze defensive play in professional soccer - A scoping review. International Journal of Sports Science & Coaching, 17, 1567 - 1592. https://doi.org/10.1177/17479541221075734.
	5. menjelaskan gambar 2.1 tentang contoh visualisasi analisis sepak bola khusus nya pada tracking data; refer; figure (2.1) 4 example (a,b,c,d) Visualization of exemplary key performance indicators: a : visualization of intra-team synchronization on dyad level, with perfect synchronous movement behavior at the top (red) and asynchronous movement behavior at the bottom (blue). b: Visualization of inter-team movement synchronization of opposing teams’ centroids. c: Visualization of the measurement of the height of the defensive line (blue). d: Visualization of the measurement of defensive pressure: Two defending players (black) exerting defensive pressure on an attacking player (blue) with the threat direction towards the goal (red arrow).
Forcher, L., Altmann, S., Forcher, L., Jekauc, D., & Kempe, M. (2022). The use of player tracking data to analyze defensive play in professional soccer - A scoping review. International Journal of Sports Science & Coaching, 17, 1567 - 1592. https://doi.org/10.1177/17479541221075734.

2.2 Expected Goals (xG)
	1. penjelasan tentang xG, gunakan referensi ini:Expected goals is a measure that quantifies how likely a given shot is to result in a goal, and is a superior predictor of a football team's future success compared to traditional statistics. 
Mead, J., O’Hare, A., & McMenemy, P. (2023). Expected goals in football: Improving model performance and demonstrating value. PLOS ONE, 18. https://doi.org/10.1371/journal.pone.0282295.

	2. penjelasan mendalam tentang xg, gunakan referensi ini:expected goals assigns a probability between 0 and 1 to each shot taken by a team in a game (0 indicating no possibility of the shot being a goal and 1 indicating a definite goal). This is a better way of dealing with the randomness in football for example, a traditional goal-based metric since a shot is a much more common event a goal. Mead, J., O’Hare, A., & McMenemy, P. (2023)

	3 & 4. penjelasan mendalam tentang xg, gunakan referensi iini: Not only can it help to improve the fortunes of football clubs on the pitch through tactical
analysis of player and team performance, but it can also assist in financial situations such as
player acquisition and contract negotiation. This is where xG’s true power lies. 
Mead, J., O’Hare, A., & McMenemy, P. (2023)

	5. penjelasan mendalam tentang xg, gunakan referensi ni: At its core, the concept of expected goals can be thought of as a classification problem (due to it being a
probability of a shot being on target) this is why, in order to calculate these probabilities,
machine learning and statistical methods are applied. Different approaches to modelling xG
include logistic regression, gradient boosting, neural networks, support vector machines and
tree-based classification algorithms Herbinet, C. (2018). Predicting football results using machine learning techniques. MEng thesis, Imperial College London. https://www.imperial.ac.uk/media/imperial-college/faculty-of-engineering/computing/public/1718-ug-projects/Corentin-Herbinet-Using-Machine-Learning-techniques-to-predict-the-outcome-of-profressional-football-matches.pdf

	6. Penjelasan xG dengan contoh gambar (snapshot dari pertandingan sepak bola) (gambar 2.2), gunakan referensi ini; Not all xG models take into account the same factors. For example, a standard Expected Goals model that only features distance to goal, angle to goal, body part, and type of assist or previous action might value a given shot at 0.30 xG. A more precise model such as Hudl Statsbomb xG adds key information such as goalkeeper position and status, the position of all attackers and defenders in frame, and shot impact height to give a more accurate picture of chance quality. For instance, knowing the goalkeeper was out of position, it might give the same chance a value of 0.65 xG. https://statsbomb.com/soccer-metrics/expected-goals-xg-explained/ 

2.3 Machine Learning
	1. menjelaskan pengertian ML, gunakan referensi ini; Machine learning is the capacity of systems to learn from problem-specific training data to automate the process of analytical model building and solve associated tasks. 
Janiesch, C., Zschech, P., & Heinrich, K. (2021). Machine learning and deep learning. Electronic Markets, 31, 685 - 695. https://doi.org/10.1007/s12525-021-00475-2.
	2. melanjutkan menjelaskan pengertian ml secara mendalam,gunakan referensi ini; Machine learning is a form of AI that uses data to train a computer to perform tasks, using algorithms to build rulesets automatically. 
Schneider, W., & Guo, H. (2018). Machine Learning.. The journal of physical chemistry. B, 122 4, 1347 . https://doi.org/10.1021/acs.jpcb.8b00035.
	3. menjelaskan perbedaan tentang ML dengan hal lain, gunakan referensi ini; Machine learning differs from data mining and traditional statistics in philosophical and methodological aspects, with three approaches: classical statistics, Vapnik's statistical learning theory, and computational learning theory.
Kodama, H., Mendori, T., Watanabe, Y., & Ohashi, K. (2023). Construction of grinding wheel decision support system using random forests for difficult-to-cut material. In Precision Engineering (Vol. 84, pp. 162–176). Elsevier BV. https://doi.org/10.1016/j.precisioneng.2023.08.004
	4. melanjutkan penjelasan perbedaan ml dengan lainya, gunakan referensi ini; Machine learning algorithms can interpret, understand, and summarize patterns and regularities in observed data for making predictions more sophisticated than traditional statistical models, with advantages in predictive capability and non-linear algorithms.
Grebovic, M., Filipović, L., Katnic, I., Vukotić, M., & Popović, T. (2023). Machine learning models for statistical analysis. Int. Arab J. Inf. Technol., 20, 505-514. https://doi.org/10.34028/iajit/20/3a/8.
	5. menjelaskan pengimplementasian ML menjelas kan gambar 2.3 (contoh implementasi ml dengan visual recognition app) Jordan, M. I., & Mitchell, T. M. (2015). Machine learning: Trends, perspectives, and prospects. In Science (Vol. 349, Issue 6245, pp. 255–260). American Association for the Advancement of Science (AAAS). https://doi.org/10.1126/science.aaa8415
	6. menjelaskan kategori-kategori dan tipe machine learning, gunakan refer ini; Machine learning styles in computer vision include supervised, unsupervised, and reinforcement learning, with various techniques like zero-shot learning, active learning, contrastive learning, self-supervised learning, and semi-supervised learning. menjelaskan juga gambar 2.4 (contoh implementasi supervised learning)
Mahadevkar, S., Khemani, B., Patil, S., Kotecha, K., Vora, D., Abraham, A., & Gabralla, L. (2022). A Review on Machine Learning Styles in Computer Vision—Techniques and Future Directions. IEEE Access, 10, 107293-107329. https://doi.org/10.1109/ACCESS.2022.3209825.
	7. menjelaskan tentang algoritma-algoritma dasar dalam Ml, gunakan refer ini; Basic algorithms in machine learning include decision tree, random forest, artificial neural network, SVM, Boosting and Bagging algorithm, and BP algorithm.
Jin, W. (2020). Research on Machine Learning and Its Algorithms and Development. Journal of Physics: Conference Series, 1544. https://doi.org/10.1088/1742-6596/1544/1/012003.
	8. menjelaskan tentang matriks evaluasi dalam Ml, gunakan refer ini; Performance metrics in machine learning are logical and mathematical constructs designed to measure how close the predicted outcome is to the actual result.
Plevris, V., Solorzano, G., Bakas, N., El, M., & Seghier, A. (2022). Investigation of performance metrics in regression analysis and machine learning-based prediction models. 8th European Congress on Computational Methods in Applied Sciences and Engineering. https://doi.org/10.23967/eccomas.2022.155.
	9. menjelaskan apa saja matriks evaluasi yang sering digunakan, gunakan refer ini; The most widely used evaluation metrics in machine learning include root mean squared error, mean absolute error, Pearson correlation coefficient, and coefficient of determination. 
Sumber sama dengan sebelumnya!

2.4 Gradient Boosting
	1. penjelasan Gradient booting, gunakan refe ini; Gradient boosting is a powerful machine learning technique that is particularly successful for tasks containing heterogeneous features and noisy data. While gradient boosting classification models return a distribution over class labels, regressions models typically yield only point predictions.
Ustimenko, A., Prokhorenkova, L., & Malinin, A. (2021). Uncertainty in Gradient Boosting via Ensembles. ArXiv.
	2. penjelasan rumus Gradient boosting pada Rumus 2.1; refer; Boosting algorithms combine weak learners, i.e. learners slightly better than random, into a strong learner in an iterative way [19]. Gradient boosting is a boosting-like algorithm for regression [9]. Given a training dataset D = {xi,yi}N 1 , the goal of gradient boosting is to find an approximation, ˆ F(x), of the function F∗(x), which maps instances x to their output values y, by minimizing the expected value of a given loss function L(y,F(x)). Gradient boosting builds an additive approximation of F∗(x) as a weighted sum of functions: rumus 2.1 : F_m (x)= F_(m-1) (x)+ρ_m h_m (x)
Bentéjac, C., Csörgő, A., & Martínez-Muñoz, G. (2020). A comparative analysis of gradient boosting algorithms. In Artificial Intelligence Review (Vol. 54, Issue 3, pp. 1937–1967). Springer Science and Business Media LLC. https://doi.org/10.1007/s10462-020-09896-5
	3. penjelasan lanjutan rumus, refer; where ρm is the weight of the mth function, hm(x). These functions are the models of the ensemble (e.g. decision trees). The approximation is constructed iteratively. First, a constant approximation of F∗(x) is obtained as : (equation 2.2)
Bentéjac, C., Csörgő, A., & Martínez-Muñoz, G. (2020). A comparative analysis of gradient boosting algorithms. In Artificial Intelligence Review (Vol. 54, Issue 3, pp. 1937–1967). Springer Science and Business Media LLC. https://doi.org/10.1007/s10462-020-09896-5
	4. penjelasan lanjutan rumus, refer;Subsequent models are expected to minimize: (equation 2.3 : (ρ_m,h_m (x))=(argmin)┬(ρ,h)⁡∑_(i=1)^N▒L(y_i,F_m-1(x_i )+ρh(x_i )) ). However, instead of solving the optimization problem directly, each hm can be seen as a greedy step in a gradient descent optimization for F∗. For that, each model, hm, is trained on a new dataset D = {xi,rmi}N i=1, where the pseudoresiduals, rmi, are calculated by: (equation 2.4 : r_mi=[∂L(Y_i,F(x))/∂L(x) ]_(F(x)=F_(m-1(x) ) )). The value of ρm is subsequently computed by solving a line search optimization problem. This algorithm can suffer from over-fitting if the iterative process is not properly regularized [9]. For some loss functions (e.g. quadratic loss), if the model hm fits the pseudo-residuals perfectly, then in the next iteration the pseudo-residuals become zero and the process terminates prematurely. To control the additive process of gradient boosting, several regularization parameters are considered. The natural way to regularize gradient boosting is to apply shrinkage to reduce each gradient decent step.
Bentéjac, C., Csörgő, A., & Martínez-Muñoz, G. (2020). A comparative analysis of gradient boosting algorithms. In Artificial Intelligence Review (Vol. 54, Issue 3, pp. 1937–1967). Springer Science and Business Media LLC. https://doi.org/10.1007/s10462-020-09896-5
	5. penjelasan pembeda antara gradient boosting dengan boosting lain, refer; Gradient boosting uses concepts from classification theory for estimation and selection of predictor effects in regression models, accounting for random effects and offering an organic and unbiased fitting approach.
Griesbach, C., Säfken, B., & Waldmann, E. (2020). Gradient boosting for linear mixed models. The International Journal of Biostatistics, 17, 317 - 329. https://doi.org/10.1515/IJB-2020-0136.
	6. lanjut penjelasan pembeda, refer; Gradient boosting can generate improvements to a nonconstant model, containing prior knowledge or physical insight about the data generating process.
Wozniakowski, A., Thompson, J., Gu, M., & Binder, F. (2021). A new formulation of gradient boosting. Machine Learning: Science and Technology, 2. https://doi.org/10.1088/2632-2153/ac1ee9.
	7. penjelasan gradient boosting dengan refer ini; Gradient Boosting, an emerging Ensemble Learning algorithm, combines weak learners to generate better predictions for bioprocess dynamic modeling and prediction, outperforming artificial neural networks. 
Mowbray, M., Rio-Chanona, E., Harun, I., Jonathan, L., Hellgardt, K., & Zhang, D. (2020). Ensemble Learning for bioprocess dynamic modelling and prediction. . https://doi.org/10.22541/au.158456506.69710259.
	8. menjelaskan parameter pada gradient boosting; refer; Parameters in gradient boosting include number of nodes, maximum depth, and learning rate, which are adjusted based on the performance of the verification set.
Hu, M., Guo, L., Liu, J., & Song, Y. (2023). Classification and Recognition of Building Appearance Based on Optimized Gradient-Boosted Decision Tree Algorithm. Sensors (Basel, Switzerland), 23. https://doi.org/10.3390/s23115353.

2.5 Light Gradient Boosting Machine (LGBM)
	1. menjelaskan penjelasan umum LGBM, gunakan refer ini; LightGBM is a framework for implementing the GBDT algorithm, offering faster training speed, lower memory consumption, better accuracy, and distributed support for handling large amounts of data.
Huang, J., & Chen, W. (2023). A Study on Category Classification Based on LightGBM for Signal Feature Extraction and K-Means Clustering. 2023 IEEE 5th International Conference on Power, Intelligent Computing and Systems (ICPICS), 858-862. https://doi.org/10.1109/ICPICS58376.2023.10235522.
	2. menjelaskan sejarah LGBM, gunakan refer ini; LightGBM is one of the most recent types of Gradient Boosting Decision Trees (GBDT). This model was developed by a team of researchers at Microsoft in 2016. It was created as an improvement over one of the most popular models- XGBoost, which is known for its speed and reliability in multi-class classification projects. The need to enhance XGBoost arose for a very obvious reason– to achieve even greater efficiency and faster implementation. As mentioned, the most computationally intensive task in GBDT is the search for optimal split points. This complexity is directly proportional to both the number of features and the number of instances. Consequently, when dealing with large datasets, we encounter speed-related issues. It was proposed to reduce the number of data instances and the number of functions. This led to the introduction of two new techniques: Gradient-based One-Side Sampling(GOSS)and Exclusive Feature Bundling (EFB).These innovations were aimed at mitigating the computational challenges associated with GBDT training on large datasets.
Kriuchkova, A., Toloknova, V., & Drin, S. (2024). Predictive model for a product without history using LightGBM. Pricing model for a new product. In Mohyla Mathematical Journal (Vol. 6, pp. 6–13). National University of Kyiv - Mohyla Academy. https://doi.org/10.18523/2617-7080620236-13
	3. penjelasan kegunaan LGBM dalam banyak masalah/subjek; refer; The improved LightGBM model can solve multi-objective multi-UAV task intelligence assignment problems with better solutions and larger solution set coverage than other algorithms. 1; LightGBM exhibits superior performance in prediction precision, model stability, and computing efficiency for genomic selection-assisted breeding in crops. 2; LightGBM model has a higher level discrimination rate (0.9 at level 6), faster training speed (28 seconds), and better discriminative accuracy compared to other procedures in enterprise management efficiency enhancement. 3; LightGBM significantly outperforms RF and LSTM algorithms in prediction accuracy and computation cost for predicting building thermal load. 4;
[1]. Wang, Y., & Zhang, G. (2023). Multi-UAV Aerial Mission Intelligent Assignment Algorithm Based on LightGBM Model. Applied Mathematics and Nonlinear Sciences, 0. https://doi.org/10.2478/amns.2023.1.00358.
[2]. Yan, J., Xu, Y., Cheng, Q., Jiang, S., Wang, Q., Xiao, Y., Ma, C., Yan, J., & Wang, X. (2021). LightGBM: accelerated genomically designed crop breeding through ensemble learning. Genome Biology, 22. https://doi.org/10.1186/s13059-021-02492-y.
2.5 Knowledge Discoveries in Databases
[3]. Xi, X. (2023). The role of LightGBM model in management efficiency enhancement of listed agricultural companies. Applied Mathematics and Nonlinear Sciences, 0. https://doi.org/10.2478/amns.2023.2.00386.
[4]. Chen, Y., Ye, Y., Liu, J., Zhang, L., Li, W., & Mohtaram, S. (2023). Machine Learning Approach to Predict Building Thermal Load Considering Feature Variable Dimensions: An Office Building Case Study. Buildings. https://doi.org/10.3390/buildings13020312.
	4. menjelaskan tentang leaf-wise tree growth pada LGBM; refer; Most decision tree learning algorithms grow trees by level (depth)-wise, like the following image (gambar 2.5). In LightGBM, growth of the tree is not same as in traditional GBDTs. Instead of considering each node equal, we focus on the ones promising the biggest improvement. That’s the core idea of LightGBM’s leaf wise tree growth strategy. (gambar 2.6)

Greedy Growth: Unlike traditional methods that consider all leaves at a level, LightGBM finds the leaf that will most improve the model’s accuracy and only splits that one. Think of it as pruning out unnecessary branches, focusing on the most fruitful path.
Asymmetrical Trees: This targeted approach can lead to asymmetrical trees, where branches develop unevenly, with some parts growing deeper than others. It’s not about perfection, but about maximizing accuracy with fewer resources. 
Benefits of leaf-wise tree growth:

Speed: Leaf-wise tree growth focuses on the most impactful splits. Which makes LightGBM incredibly fast. Also by this method LightGBM avoids expanding subtrees which doesn’t impact more on model.
Accuracy: Leaf-wise growth often leads to lower loss and higher accuracy by prioritizing the most informative regions.
LightGBM Contributors. (2024). LightGBM installation guide [Documentation]. Microsoft. Retrieved October 28, 2024, from https://lightgbm.readthedocs.io/en/stable
	5. penjelasan tools dan library LGBM; refer; To implement LightGBM, you primarily need the LightGBM library itself, which can be installed through your package manager depending on your programming language (Python, R, etc.), and often requires supporting libraries like CMake for building and potentially CUDA libraries if you want to leverage GPU acceleration for faster computations.
LightGBM Contributors. (2024). LightGBM installation guide [Documentation]. Microsoft. Retrieved October 28, 2024, from https://lightgbm.readthedocs.io/en/stable
	6. menjelaskan Bagaimana memastikan interpretabilitas dan keterbukaan model yang dikembangkan dengan LightGBM, refer; Interpretation techniques like permutation feature importance (PFI) and Shapley additive explanations (SHAP) can help explain and improve the predictions of machine learning models like LightGBM.
Chaibi, M., Benghoulam, E., Tarik, L., Berrada, M., & Hmaidi, A. (2021). An Interpretable Machine Learning Model for Daily Global Solar Radiation Prediction. Energies. https://doi.org/10.3390/en14217367.
	7. menlajutkan penjelasan paragraf 5, refer; Using SHAP values for LightGBM predictions can ensure interpretability and openness, improving inference performance, training time, and reducing "fitting-to-noise" for complex datasets. 
Bugaj, M., Wrobel, K., & Iwaniec, J. (2021). Model Explainability using SHAP Values for LightGBM Predictions. 2021 IEEE XVIIth International Conference on the Perspective Technologies and Methods in MEMS Design (MEMSTECH), 102-106. https://doi.org/10.1109/MEMSTECH53091.2021.9468078.
	8. melanjutkan penjelasan paragraf 6 dengan penjelasan dari refer ini; LightGBM can ensure interpretability and openness by allowing users to steer the model synthesis process according to their preferences using a bi-objective evolutionary algorithm and personalized interpretability estimation (ML-PIE).
Virgolin, M., Lorenzo, A., Randone, F., Medvet, E., & Wahde, M. (2021). Model learning with personalized interpretability estimation (ML-PIE). Proceedings of the Genetic and Evolutionary Computation Conference Companion. https://doi.org/10.1145/3449726.3463166.
2.6 Brier Score
	1. menjelaskan penjelasan umum tentang brier score; refer; The Brier score is the sum of the calibration score and the refinement score, measuring expertise in predictive modeling by sorting into bins with the same forecast.
Foster, D., & Hart, S. (2022). "Calibeating": Beating Forecasters at Their Own Game. ArXiv, abs/2209.04892. https://doi.org/10.48550/arXiv.2209.04892.
	2. menjelaskan kenapa mengapa dalam model probabilitas menggunakan brier score dalam evaluasi modelnya, refer; The Brier score is used for evaluating probability models because it measures discrimination ability and overall predictive performance.
Dimitriadis, T., Gneiting, T., Jordan, A., & Vogel, P. (2023). Evaluating Probabilistic Classifiers: The Triptych. ArXiv, abs/2301.10803. https://doi.org/10.48550/arXiv.2301.10803.
	3. menjelaskan rumus brier score; persamaan 2.5; Brier Score =(f_t- o_t )^2
BMJ Open. (2018). Supplementary file 2 [Supplemental material]. BMJ Open. https://doi.org/10.1136/bmjopen-2018-024996.supp2
	4. fokus menjelaskan sejarah brier score; refer; The difference between the two forecasts is underscored by appealing to the classic Brier (1950) score B, which measures how close the forecasts and the realizations are, by the standard mean squared error formula
Foster, D., & Hart, S. (2022). "Calibeating": Beating Forecasters at Their Own Game. ArXiv, abs/2209.04892. https://doi.org/10.48550/arXiv.2209.04892.
	5. lanjut sejarah brier score; rfer; Scoring rules were first suggested for evaluate meteorological forecasts in work by Brier (1950). Scoring rules have since been used in a wide variety of settings, such as business and other applications.
Petropoulos, F., Apiletti, D., Assimakopoulos, V., Babai, M. Z., Barrow, D. K., Ben Taieb, S., Bergmeir, C., Bessa, R. J., Bijak, J., Boylan, J. E., Browell, J., Carnevale, C., Castle, J. L., Cirillo, P., Clements, M. P., Cordeiro, C., Cyrino Oliveira, F. L., De Baets, S., Dokumentov, A., … Ziel, F. (2022). Forecasting: theory and practice. International Journal of Forecasting (Vol. 38, Issue 3, pp. 705–871). Elsevier BV. https://doi.org/10.1016/j.ijforecast.2021.11.001


2.7 Receiver Operating Characteristic Area Under Curve (ROC AUC)
	1. penjelasan ROC AUC; refer; ROC analyses are based on a characterization of statistical evidence, using prior distributions and elicitation algorithms to guide the selection of priors, resulting in inferences for the AUC (Area Under the Curve) and error characteristics.
Labadi, L., Evans, M., & Liang, Q. (2022). ROC Analyses Based on Measuring Evidence Using the Relative Belief Ratio. Entropy, 24. https://doi.org/10.3390/e24121710.
	2. melanjutkan paragraf 1; refer; ROC is a tool used to evaluate the relative performance of testing devices and classification algorithms in assessing compliance.
Pendrill, L., Melin, J., Stavelin, A., & Nordin, G. (2023). Modernising Receiver Operating Characteristic (ROC) Curves. Algorithms, 16, 253. https://doi.org/10.3390/a16050253.
	3. melanjutkan paragraf 3; refer;TheROCcurveisagraph showing the performance of a classification model at all classification thresholds which plots two parameters: TPR and FPR. One potential drawback of the ROC curve is that it can be difficult to interpret if there are many decision thresholds. This is because each point on the curve represents a different tradeoff between the TPR and FPR, and it may not be immediately clear which point represents the best overall performance of the algorithm. AUC measures the entire two-dimensional area underneath the entire ROC curve from (0,0) to (1,1). A higher AUC indicates that the model performs better in distinguishing between positive and negative classes.
Chen, Z., O’Neill, Z., Wen, J., Pradhan, O., Yang, T., Lu, X., Lin, G., Miyata, S., Lee, S., Shen, C., Chiosa, R., Piscitelli, M. S., Capozzoli, A., Hengel, F., Kührer, A., Pritoni, M., Liu, W., Clauß, J., Chen, Y., & Herr, T. (2023). A review of data-driven fault detection and diagnostics for building HVAC systems. Applied Energy (Vol. 339, p. 121030). Elsevier BV. https://doi.org/10.1016/j.apenergy.2023.121030
	4. menjelaskan gambar 2.7 adalah contoh ROC AUC; refer;  A receiver operating characteristic (ROC) curve connects coordinate points with 1 - specificity (= false positive rate) as the x-axis and sensitivity as the y-axis at all cut-off values measured from the test results. When a strict cut-off point (reference) value is applied, the point on the curve moves downward and to the left (Point A). When a loose cut-off point value is applied, the point moves upward and to the right (Point B). The 45° diagonal line serves as the reference line, since it is the ROC curve of random classification.
Nahm, F. S. (2022). Receiver operating characteristic curve: overview and practical use for clinicians. In Korean Journal of Anesthesiology (Vol. 75, Issue 1, pp. 25–36). The Korean Society of Anesthesiologists. https://doi.org/10.4097/kja.21209
	5. penjelasan pentingnya ROC AUC;refer; ROC AUC is important for model evaluation because it evaluates performance in multiple groups of predicted risk, providing depth in information for decision-making.
Carrington, A., Manuel, D., Fieguth, P., Ramsay, T., Osmani, V., Wernly, B., Bennett, C., Hawken, S., Magwood, O., Sheikh, Y., McInnes, M., & Holzinger, A. (2021). Deep ROC Analysis and AUC as Balanced Average Accuracy, for Improved Classifier Selection, Audit and Explanation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45, 329-341. https://doi.org/10.1109/TPAMI.2022.3145392.
	6. lanjut penjelasan paragraf 5; refer; AUC-ROC is important for model evaluation because it enables a reasonable comparison between models and helps identify decision boundaries and headroom to improve AUC.
Tafvizi, A., Avci, B., & Sundararajan, M. (2022). Attributing AUC-ROC to Analyze Binary Classifier Performance. ArXiv, abs/2205.11781. https://doi.org/10.48550/arXiv.2205.11781.

2.8 Knowledge Discovery in Databases (KDD)
	1. penjelasan umum KDD; refer; KDD is the process of extracting interpretable, intriguing, and valuable statistics from unstructured data, used in various areas like life sciences, commerce, finance, and medicine.
Solanki, M., & Sharma, M. (2021). A Review of Data Mining Techniques and Its Applications. International Journal of Innovative Research in Computer Science & Technology. https://doi.org/10.55524/ijircst.2021.9.6.23.
	2. penjelasan lanjut; refer; KDD is a field that uses intelligent methods in data mining to discover patterns that are the essence of knowledge.
Atloba, F., Balkir, N., & El-Mouadib, F. (2021). An Enhanced Version of K-means Algorithm. The 7th International Conference on Engineering & MIS 2021. https://doi.org/10.1145/3492547.3492592.
	3. penjelasan steps KDD; refer; The KDD process has been formed by different stages, which iteratively interact with each other. During the years, several models have been proposed.Generally, the process of knowledge discovery can be divided into following stages: 1. Data cleaning (the removal of noise and inconsistent data) 2. Data integration (combining multiple data sources) 3. Data selection (retrieval of data relevant to the analysis task from the database) 4. Data transformation (transformation or consolidation of data suited for mining; this can be done, for example by performing summary or aggregation operations) 5. Data mining (an essential process where intelligent methods are applied in order to extract data patterns) 6. Pattern evaluation (used to identify the most interesting patterns representing knowledge based on some interestingness measures) 7. Knowledge presentation (use of visualization and knowledge representation techniques to present the mined knowledge to the user)
Chaudhary, K. K., & Kishore, A. (2017). KNOWLEDGE DISCOVERY IN DATABASES (KDD): EVOLUTION, BASIC FEATURES, PROCESS, STEPS, CHALLENGES, ROLE & APPLICATIONS. LORD'S PUBLISHING HOUSE, 63. 
	4. penjelasan lanjutan dari step; refer; Data Mining is an essential part in the global process of knowledge discovery. It involves a collection of tools and techniques for finding useful patterns relating the fields of very large databases. The newest form of data mining is the linguistic summarization of data which aims at a computer generated verbal description of the knowledge implicit in a database often in the form of ‘if  then’ rules that resemble fuzzy knowledge granules. Text mining is to extract patterns from textual documents. A text mining technique typically involves text parsing and analysis to transform each unstructured document into an appropriate set of features and subsequently applies one or more data mining techniques for extracting patterns.
Chaudhary, K. K., & Kishore, A. (2017). KNOWLEDGE DISCOVERY IN DATABASES (KDD): EVOLUTION, BASIC FEATURES, PROCESS, STEPS, CHALLENGES, ROLE & APPLICATIONS. LORD'S PUBLISHING HOUSE, 63.
	5 penjelasan tentang kaitan dengan ML; refer; Machine learning in KDD helps analyze data, recognize correlations, and predict outcomes.
Kodati, S., & Selvaraj, J. (2021). Analysis of Heart Disorder by Using Machine Learning Methods and Data Mining Techniques. , 212-221. https://doi.org/10.4018/978-1-7998-2108-3.ch009.
	6. penjelasan aplikasi KDD dalam berbagai industri; refer; KDD applications in healthcare include developing medical systems that detect and suggest cures for ailments with minimal effort.; The proposed gradient boosting machine-based KDD framework is effective and reliable for electricity energy prediction, providing practical references for other types of energy KDD applications.
Nwankwo, U.C. Ngene, N.J, & Onuora, J.N. (2023). APPLICATIONS OF KNOWLEDGE DISCOVERY AND DATABASE (KDD) IN CLINICAL DECISION SUPPORT SYSTEM. Engineering and Technology Journal. https://doi.org/10.47191/etj/v8i11.02.
Xie, B., Zhu, C., Zhao, L., & Zhang, J. (2022). A gradient boosting machine-based framework for electricity energy knowledge discovery. , 10. https://doi.org/10.3389/fenvs.2022.1031095.
	7. menjelaskan keterkaitan KDD dengan analisis olahraga khususnya sepak bola; refer; A comprehensive KDD approach allows for the appropriate preparation of data for sports prediction on sports data, including football match results.
Głowania, S., Kozak, J., & Juszczuk, P. (2023). Knowledge Discovery in Databases for a Football Match Result. Electronics. https://doi.org/10.3390/electronics12122712.
